Использованные библиотки:
- NumPy
- Pandas
- Sklearn

Пример, создание системы рекомендации по описанию книг

Для налача создадим словарь с названиям книг и описанием

```python
book = {
"Название книги": [
	'Книга 1',
	'Книга 2',
	'Книга 3',
	],
"Описание": [
	'Описание книги 1',
	'Описание книги 2',
	'Описание книги 3',
	],
}
```

Преобразуем при помощи pandas book в дата-фрейм.
`df_books = pd.DataFrame(books)`

**- *DataFrame** — двумерный массив (таблица)*

Преобразуем текст в числовые вектора с использованием TF-IDF

```python
tfidf = TfidfVectorizer(stop_words='english')

tfidf_matrix = tfidf.fit_transform(df_books['Описание'])
```

**TF-IDF** (от англ. TF — term frequency, IDF — inverse document frequency) — статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции.

**Термины "TF" (Term Frequency) и "IDF" (Inverse Document Frequency)**

- TF (*Частота термина*) обозначает, насколько часто определенное слово появляется в данном документе. Таким образом, TF измеряет важность слова в контексте отдельного документа.
Вычесляется:
$$
n/sum(n)+k
$$
где, n-определённое слово, k- остальные слова документа

- IDF (*Обратная частота документа*) измеряет, насколько уникально слово является по всей коллекции документов. Слова, которые появляются в большинстве документов, имеют низкое IDF, так как они не вносят большой информационной ценности.
Вычесляется:
$$
log (d/dn)
$$
где, d - кол-во всех документов, dn - кол-во документов встречающее слово "n"

**Формула вычисления TF-IDF**

Формула TF-IDF комбинирует понятия TF и IDF, чтобы вычислить важность каждого слова в каждом документе. Формально, формула выглядит следующим образом:
	
**TF-IDF(t, d) = TF(t, d) * IDF(t)**

где:
- **TF(t, d)** - Частота термина (TF) для слова "t" в документе "d".
- **IDF(t)** - Обратная частота документа (IDF) для слова "t".

Используйем `stop_words` для удаления менее значимых английских слов.

Список стоп-слов, которые использует sklearn, можно найти по адресу:

```python
from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS
```

`TfidfVectorizer` Преобразует коллекцию необработанных документов в матрицу функций TF-IDF. Это обычный шаг в задачи обработки естественного языка (НЛП) и интеллектуальный анализ текста для преобразования текстовых данных в числовые, с помощью алгоритмов машинного обучения.

 Как работает TfidfVectorizer

1. *Частота использования термина (TF)*: Исследования определяют применение термина (слова) в документе.Предполагается, что чем чаще термин встречается в документе, тем он важнее.Однако само по себе это может ввести в заблуждение, поскольку во многих документах часто встречаются общеупотребительные слова (например, «the», «is», «i»).
2. *Обратная цена документов (IDF)*: этот показатель важности термина с учетом того, что он часто встречается во всех документах в наборе данных.Чем в большем количестве документов появляется термин, тем менее он важен.Значение IDF для термина переносится по мере увеличения количества документов, содержащих термин.
3. *TF-IDF: Продукт TF и ​​IDF*.Это дает нам представление о том, что в данном документе очень важен термин, при одновременном снижении веса часто встречаются термины, которые менее информативны.

Cоздадим два списка: один с названиями книг, другой с их описаниями, которые можно использовать для дальнейшей обработки, например, для расчета сходства.

```python
name_book = df_books['Название'].tolist()
description_book = df_books['Описание'].tolist()
```

Функция `tolist()` в Python используется для преобразования заданного массива в обычный список с теми же элементами, элементами или значениями.

Метод `fit_transform()` сразу вычисляет статистические показатели и применяет их для масштабирования данных.

Рассчитаем косинусное сходство между книгами
```python
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
```

**Косинусное сходство** — это метод, используемый при создании приложений машинного обучения, таких как рекомендательные системы. Он **используется для поиска сходства между двумя документами**.

**Косинусное подобие** - это косинус угла между векторами; то есть это скалярное произведение векторов, деленное на произведение их длин. Отсюда следует, что косинусное подобие зависит не от величин векторов, а только от их угла. Косинусное сходство всегда относится к интервалу [−1,1]. 

Если значение показателя сходства между двумя векторами равно 1, это означает, что существует большое сходство между двумя векторами.

С другой стороны, если значение оценки сходства между двумя векторами равно 0, это означает, что между двумя векторами нет никакого сходства. Когда показатель подобия равен 1, угол между двумя векторами равен 0, а когда показатель сходства равен 0, угол между двумя векторами составляет 90 градусов.

*Идея заключается в том, чтобы создать два массива, а затем реализовать метод «cosine_similarity», предоставленный в библиотеке Scikit-Learn, чтобы найти сходство между ними.*

Создадим функцию для получения рекомендации

```python
def recommend_books(book_title, cosine_sim=cosine_sim):
    idx = df_books[df_books['Название'] == book_title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]
    book_indices = [i[0] for i in sim_scores]
    recommendations = [name_book[i] for i in book_indices]

    for i, book in enumerate(recommendations, 1):
        print(f"Книга {i}: {book}")
```

Для начала найдём индекс книги, соотвествующей по названию `idx = df_books[df_books['Название книги'] == book_title].index[0]` Затем получает список коэффициентов схожести для данной книги `sim_scores = list(enumerate(cosine_sim[idx]))` 

`enumerate()` Эта функция возвращается в формате пар ключ-значение, где ключи — это соответствующие индексы элементов, а значения — сами элементы из переданного набора данных.
- `iterable` — это итерируемый объект (список, кортеж и т.д.), который будет возвращен в виде пронумерованного объекта (объекта enumerate)
- `start` — это начальный индекс для возвращаемого объекта enumerate. Значение по умолчанию равно 0, поэтому, если вы опустите этот параметр, в качестве первого индекса будет использоваться 0.

Затем отсортируем книги по коэффициенту схожести `sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
`
- `reverse` (необязательный параметр): по умолчанию сортировка выполняется по возрастанию. Если указать `reverse=True`, то можно отсортировать по убыванию.

Получим индексы самых похожих книг (пропускаем первую книгу - это сама книга)
`sim_scores = sim_scores[1:2]`

Можно указать больше, но остановимся на 1 книге следующей, для примера наглядности можно изменить параметр на `sim_scores = sim_scores[1:6]`

Вернём название книг
```python
book_indices = [i[0] for i in sim_scores]
    recommendations = [name_book[i] for i in book_indices]
    for i, book in enumerate(recommendations, 1):
        print(f"Книга {i}: {book}")
```


Например использования: рекомендуем книги, если пользователь купил 'Язык программирования C. Лекции и упражнения | Прата Стивен'
```python
print("Рекомендации для книги 'Data Science. Наука о данных с нуля | Грас Джоэл':")

recommend_books('Data Science. Наука о данных с нуля | Грас Джоэл')
```

Рекомендуемая книга:
*/>*Рекомендации для книги 'Язык программирования C. Лекции и упражнения | Прата Стивен':
	Книга 1: Программируем на Python | Доусон Майкл

Список 5 рекомендуемых книг:
*/>Рекомендации для книги 'Язык программирования C. Лекции и упражнения | Прата Стивен':
	Книга 1: Программируем на Python | Доусон Майкл
	Книга 2: Философия Java. 4-е полное изд. | Эккель Брюс
	Книга 3: Python для детей. Самоучитель по программированию | Бриггс Джейсон
	Книга 4: Структуры данных и алгоритмы в Java | Лафоре Роберт
	Книга 5: Oracle для профессионалов. | Кайт Томас, Дарл Кун

Вывод, рекомендательная система на данных описания книг и выбранной книги, вывела рекомендации для пользователя. Так как на основе лежит, анализ описание книги, то содержание может отличаться. Для лучшей эффективности, нужно использовать вместо описания содержание книги. 

Проведём небольное исследование в качестве исходных данных названий и описания книг возьмем из файла /Система рекомендации/RS-book.py

В качестве первой книги возьмём *Data Science. Наука о данных с нуля Грас Джоэл Грас Джоэл | Грас Джоэл*. Выявим точные ограничения:
1. Книга точно не для детей
2. Изучаем основы Python. Практический курс для дата-аналитиков. (Ай Пи Ар Медиа) должна войти в рекомендации
3. Структуры данных и алгоритмы в Java | Лафоре Роберт данная книга тоже должна войти в рекомандации
4. Python, Django и Bootstrap для начинающих не очень подойдёт Data Science

На это мы получили ответ: 
*/>*Рекомендации для книги 'Data Science. Наука о данных с нуля | Грас Джоэл':
	Книга 1: Структуры данных и алгоритмы в Java | Лафоре Роберт
	Книга 2: Изучаем основы Python. Практический курс для дата-аналитиков. (Ай Пи Ар Медиа)
	Книга 3: Oracle для профессионалов. | Кайт Томас, Дарл Кун
	Книга 4: Python, Django и Bootstrap для начинающих. | Постолит Анатолий В.
	Книга 5: Python для детей. Самоучитель по программированию | Бриггс Джейсон

Мы видем, что книга Структуры данных и алгоритмы в Java | Лафоре Роберт система рекомендации выставила на 1 место. Изучаем основы Python. Практический курс для дата-аналитиков данная книга присуствует в топе. Oracle для профессионалов. Архитектура, методи... - работа с БД для Data Science тоже важно и нужно. Python, Django и Bootstrap для начинающих и Python для детей. Самоучитель по программирова.. тоже присуствуют в рекомендации, это связанно с частой повторения слов, который присуствуют в Data Science. Наука о данных с нуля Грас Джоэл Грас Джоэл | Грас Джоэл. Но всё же, 3 книги система правильно выставила в топе. Конечно, над этой системой нужно работать и работать, но она спокойно может посоветовать похожую книгу.