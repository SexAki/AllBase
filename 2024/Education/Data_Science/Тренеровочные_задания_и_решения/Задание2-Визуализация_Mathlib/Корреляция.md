Корреляция _(от лат. correlatio «соотношение»)_ — это взаимосвязь между разными показателями в статистике. Например, когда один показатель увеличивается, другой уменьшается — или тоже увеличивается. Корреляцию используют, чтобы оценить зависимость переменных друг от друга.

Коэффициенты сравнения используются для расчета того, насколько важна связь между двумя переменными.Среди различных типов корреляций коэффициентов одной из наиболее популярных является корреляция Пирсона (также известная как Р. Пирсона), которая обычно используется в линейной регрессии.

Корреляция может быть:
- положительной — когда один показатель растет, другой тоже растет;
- отрицательной — когда одна переменная растет, другая уменьшается;
- нейтральной — изменения не связаны друг с другом.

## Что показывает корреляция 

С помощью корреляции определяют, как одна переменная меняется относительно другой — это определение из статистики. Это нужно, чтобы оценить, насколько показатели могут быть взаимосвязаны.

**Корреляция — это не зависимость.** Если две переменные коррелируют друг с другом — это еще не значит, что между ними есть причинно-следственная связь. Причины корреляции нужно исследовать отдельно — чтобы понять, как именно могут быть связаны показатели.

**Корреляция может быть случайной.** Иногда друг с другом коррелируют показатели, которые вообще не связаны и никак не зависят один от другого. Понятно, что связи тут, скорее всего, нет, просто совпадение. Такое явление называют spurious correlation, или ложной корреляцией.

*Коэффициенты корреляции* — показатели, которые выражают силу корреляции между переменными. Какой коэффициент использовать — зависит от ситуации, каждый из них лучше подходит для определенных случаев.

*Статистическая корреляция* — это мощный инструмент анализа данных, который помогает выявлять связь между двумя или более переменными. Один из наиболее распространенных методов измерения корреляции — коэффициент корреляции, который может быть как положительным, так и отрицательным. Положительная корреляция указывает на то, что увеличение значений одной переменной обычно сопровождается увеличением значений другой, в то время как отрицательная корреляция указывает на обратную связь.

Вот несколько распространенных коэффициентов корреляции.

**Пирсона**. Этот коэффициент — самый популярный в статистике, описывается буквой r и показывает прямолинейную связь между переменными. Он принимает значение от -1 до 1. Чем ближе значение к 1, тем выше положительная корреляция между показателями. Если оно, наоборот, ближе к -1 — корреляция отрицательная. А близкое к 0 значение, включая сам ноль, говорит, что корреляции нет.

**Кендалла**. Этот коэффициент описывается буквой t и показывает корреляцию между факторами, которые можно ранжировать по какому-то признаку. Вместо значений показателя используют ранги — номера, присвоенные значениям при ранжировании. Проверить корреляцию Кендалла можно только для порядковых показателей — таких, которые можно упорядочить. Значение коэффициента — тоже от -1 до 1, и означают цифры то же, что и при корреляции Пирсона. Он тоже подходит только для оценки линейной связи.

**Спирмена**. Описывается буквой p.Так же как и коэффициент Кендалла, этот предназначен для оценки ранжированных показателей — но больше подходит для малых выборок. Он использует непараметрические методы, которые могут обрабатывать данные низкого качества — с погрешностями, малым количеством информации и так далее. Принимает те же значения, что и коэффициент Пирсона, и означают они то же самое.

Еще есть коэффициент фи-корреляции для бинарных переменных и коэффициент Крамера для номинальных переменных, основанный на критерии хи квадрат.

Коэффициенты существуют только для линейной корреляции, когда график одного показателя как бы «повторяет» другой. Еще есть нелинейная корреляция: одна переменная изменяется равномерно, а другая неравномерно, но взаимосвязь при этом есть. Для оценки нелинейной корреляции не пользуются коэффициентами, а используют более общий показатель — корреляционное отношение.


|Величина показателя тесноты связи|Характер связи|
|---|---|
|До \|±0,2\||Практически отсутствует|
|\|±0,2\|-\|±0,5\||Слабая|
|\|±0,5\|-\|±0,75\||Умеренная, заметная|
|\|±0,75\|-\|±0,95\||Тесная|
|\|±0,95\|-\|±0,99(9)\||Очень тесная, близкая к функциональной|
|= \|±1,0\||Функциональная|

**Коэффициент корреляции**

![[Формула Корреляции.png]]

#### Определим корреляцию, применив приведенную выше формулу:

```python
def Pearson_correlation(X,Y):
	if len(X)==len(Y):
		Sum_xy = sum((X-X.mean())*(Y-Y.mean()))
		Sum_x_squared = sum((X-X.mean())**2)
		Sum_y_squared = sum((Y-Y.mean())**2)	 
		corr = Sum_xy / np.sqrt(Sum_x_squared * Sum_y_squared)
	return corr
			
print(Pearson_correlation(x,y)) 
print(Pearson_correlation(x,x))
```

Мы также можем найти корреляцию с помощью функции numpy corrcoef.
`print(np.corrcoef(x, y))`


